{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengimport library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd, singkatan dari \"automatic differentiation,\" adalah sebuah konsep penting dalam mesin pembelajaran yang terkait dengan perhitungan gradien. Autograd mengacu pada kemampuan sistem atau pustaka mesin pembelajaran untuk secara otomatis menghitung gradien (turunan) dari suatu fungsi terhadap parameter-parameter yang ada di dalamnya.\n",
    "\n",
    "Dalam konteks neural networks dan optimasi model, autograd sangat berguna karena memungkinkan model untuk melakukan pembelajaran berbasis gradien, seperti yang terjadi selama pelatihan dengan algoritma seperti Stochastic Gradient Descent (SGD) atau varian-varian lainnya. Autograd membuat perhitungan gradien menjadi lebih efisien dan otomatis, sehingga memungkinkan model neural untuk diperbarui dengan gradien yang tepat tanpa perlu menghitung turunan secara manual.\n",
    "\n",
    "Cara kerja autograd biasanya melibatkan grafik perhitungan (computation graph) yang mencatat semua operasi matematika yang terjadi selama eksekusi suatu fungsi atau model. Setiap operasi ini dihubungkan dengan parameter-parameter yang terlibat dalam operasi tersebut, dan autograd secara otomatis melacak semua keterkaitan ini. Ketika Anda meminta gradien suatu fungsi terhadap parameter tertentu, autograd akan melakukan perhitungan balik (backpropagation) untuk menghasilkan gradien yang akurat dengan menggunakan aturan rantai (chain rule).\n",
    "\n",
    "Autograd adalah salah satu komponen penting dalam kerangka kerja deep learning seperti TensorFlow dan PyTorch, yang menyediakan fasilitas untuk menghitung gradien secara otomatis. Dengan adanya autograd, pengembang dan peneliti dapat dengan mudah melatih dan mengoptimasi model neural dengan berbagai metode pelatihan yang bergantung pada gradien, seperti backpropagation, tanpa perlu khawatir tentang perhitungan gradien secara manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install https://download.pytorch.org/whl/cu80/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pertama-tama kita akan membuat variabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Membuat variabel dengan mengaktifkan ```requires_grad```\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "\n",
    "z = y * y * 3\n",
    "z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung gradien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memanggil y.backward() untuk menghitung gradien. Hasilnya dapat diakses melalui atribut .grad pada tensor x.\n",
    "\n",
    "Dengan cara ini, PyTorch secara otomatis menghitung gradien fungsi y terhadap x, dan Anda dapat menggunakannya untuk mengoptimalkan parameter-parameter Anda saat melatih model deep learning atau dalam berbagai tugas lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dz/dx\n",
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradien diatas dapat dihitung karena nilai dari z berupa skalar dan bukan vektor. Apabila misalnya kita hanya melakukan operasi z = y * y * 3, maka nilai dari z tidak berupa vektor dan tidak dapat dihitung gradiennya. Lalu bagaimana jika ingin melakukan backpropagation terhadap nilai yang berupa vektor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "z = y * y * 3\n",
    "\n",
    "# kita membutuhkan v sebagai array yang akan membantu melakukan backward terhadap z\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "z.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghentikan Tracking Gradien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "y = torch.randn(3, requires_grad=True)\n",
    "z = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cara pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x.requires_grad_(False)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cara kedua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = y.detach()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cara ketiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = x + y\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradien yang salah akibat dari backpropagation\n",
    "Ketika kita melakukan backpropagation dengan epoch yang berjumlah lebih dari satu, maka kita akan mendapatkan nilai gradien yang salah seperti pada kode di bawah ini. Nilai dari gradien terakumulasi pada setiap perulangan epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mengatasi kesalahan di atas, maka kode di bawah ini akan menghilangkan nilai gradien yang salah dengan cara mengosongkan nilai gradien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    model_output = (weights * 3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hal yang sama juga perlu dilakukan ketika menggunakan optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "optimizer = torch.optim.SGD(weights, lr=0.01)\n",
    "optimizer.step()\n",
    "# gunakan optimizer untuk mengoptimalkan nilai weights\n",
    "optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
